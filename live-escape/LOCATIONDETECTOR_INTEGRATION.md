# LocationDetector Integration into Live-Escape ‚úÖ

## What Was Integrated

Successfully integrated **locationDetector** technology (indoor localization, GPS tracking, observation storage) into the **live-escape** emergency evacuation system UI.

## Changes Made

### 1. Client-Side (public/index.html)

#### Device ID System
- Generates unique device ID: `device_<timestamp>_<random>`
- Stores in localStorage for persistence
- Reuses same ID across sessions

```javascript
let deviceId = localStorage.getItem('device_id');
if (!deviceId) {
    deviceId = 'device_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
    localStorage.setItem('device_id', deviceId);
}
```

#### GPS Tracking
- Uses HTML5 Geolocation API with high accuracy
- Tracks latitude, longitude, accuracy
- Starts automatically on connection
- Stops on disconnect

```javascript
gpsWatchId = navigator.geolocation.watchPosition(
    (position) => {
        currentGpsData = {
            latitude: lat,
            longitude: lon,
            accuracy: acc,
            timestamp: new Date().toISOString()
        };
    },
    gpsOptions
);
```

#### Indoor Localization Prompt (Replaced Emergency Prompt)

**OLD** (Emergency Evacuation):
```
Analyze this emergency evacuation video frame and identify:
1. OBSTACLES: debris, furniture, locked doors
2. HAZARDS: Fire, smoke, water
3. PEOPLE: Count, positions, density
4. EXITS: Status, direction
```

**NEW** (Indoor Localization):
```
You are a visual perception system for indoor navigation.

Extract the following information:
1. Scene Type: hallway, room, lobby, stairwell, etc.
2. Text Detection: Room numbers, floor indicators, directional signs
3. Landmarks: door, staircase, elevator, exit_sign, etc.
4. Quality Assessment: Lighting, motion blur
```

#### Overshoot SDK Configuration

**Settings from locationDetector:**
```javascript
visionSession = new RealtimeVision({
    apiUrl: 'https://cluster1.overshoot.ai/api/v0.2',
    apiKey: 'ovs_4488f728fc52c4d2ca6f8972c7cc53e3',
    prompt: INDOOR_LOCALIZATION_PROMPT,  // Changed from emergency prompt
    video: videoElement,
    source: { type: 'camera', cameraFacing: 'environment' },
    clip_length_seconds: 1.0,
    delay_seconds: 6.0,
    fps: 10,
    sampling_ratio: 0.2,
    onResult: handleAnalysisResult
});
```

#### Parse Overshoot Result (LocationDetector Format)
- Added `parseOvershootResult()` function
- Extracts: scene_type, text_detected, landmarks, lighting_quality, motion_blur_detected
- Parses format: `Scene: hallway\nText: [301, EXIT ‚Üí]\nLandmarks: [door: left, near]`

```javascript
function parseOvershootResult(result) {
    const parsed = {
        scene_type: 'unknown',
        text_detected: [],
        landmarks: [],
        lighting_quality: 'unknown',
        motion_blur_detected: false,
        raw_response: text
    };
    // ... parsing logic
    return parsed;
}
```

#### Save Observations (GPS + Metadata)
- Added `saveObservation()` function
- Combines GPS coordinates with indoor metadata
- Saves to server via POST /save_observation

```javascript
async function saveObservation(metadata) {
    const observation = {
        device_id: deviceId,
        timestamp: currentGpsData.timestamp,
        gps_latitude: currentGpsData.latitude,
        gps_longitude: currentGpsData.longitude,
        gps_accuracy: currentGpsData.accuracy,
        metadata: metadata
    };

    await fetch('/save_observation', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(observation)
    });
}
```

#### Modified handleAnalysisResult
- Parses Overshoot result using locationDetector format
- Saves observation with GPS data
- Maps to legacy emergency format for UI compatibility

```javascript
function handleAnalysisResult(result) {
    // Parse indoor localization metadata
    const indoorMetadata = parseOvershootResult(result);

    // Save observation with GPS data
    saveObservation(indoorMetadata);

    // Map to emergency format for backward compatibility
    const analysis = {
        scene_type: indoorMetadata.scene_type,
        text_detected: indoorMetadata.text_detected,
        landmarks: indoorMetadata.landmarks,
        // ... rest of mapping
    };

    displayAnalysisResult(analysis, result);
}
```

### 2. Server-Side (src/index.ts)

#### Added Observation Storage
- Created observations directory
- Added JSON body parsing middleware
- Imported fs module

```typescript
import fs from 'fs';

app.use(express.json());

const OBSERVATIONS_DIR = path.join(__dirname, '../observations');
if (!fs.existsSync(OBSERVATIONS_DIR)) {
  fs.mkdirSync(OBSERVATIONS_DIR, { recursive: true });
}
```

#### Added API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/save_observation` | POST | Save GPS + metadata observation |
| `/observations/:device_id` | GET | Get all observations for device |
| `/devices` | GET | List all active devices with latest GPS |

**Example /save_observation:**
```typescript
app.post('/save_observation', (req, res) => {
  const { device_id, timestamp, gps_latitude, gps_longitude, gps_accuracy, metadata } = req.body;

  const deviceFile = path.join(OBSERVATIONS_DIR, `observations_${device_id}.json`);

  // Read existing observations
  let observations = fs.existsSync(deviceFile)
    ? JSON.parse(fs.readFileSync(deviceFile, 'utf-8'))
    : [];

  // Append new observation
  observations.push({ device_id, timestamp, gps_latitude, gps_longitude, gps_accuracy, metadata });

  // Save to file
  fs.writeFileSync(deviceFile, JSON.stringify(observations, null, 2));

  res.json({ status: 'success', device_id, total_observations: observations.length });
});
```

## Data Format

### Observation Structure (Saved to JSON)

```json
{
  "device_id": "device_1737172331234_abc123xyz",
  "timestamp": "2026-01-18T04:50:00.000Z",
  "gps_latitude": 37.7749295,
  "gps_longitude": -122.4194155,
  "gps_accuracy": 15.2,
  "metadata": {
    "scene_type": "hallway",
    "text_detected": [
      { "text": "301", "confidence": 0.8, "includes_arrow": false },
      { "text": "EXIT ‚Üí", "confidence": 0.8, "includes_arrow": true }
    ],
    "landmarks": [
      { "type": "door", "direction": "left", "distance": "near", "confidence": 0.75 },
      { "type": "exit_sign", "direction": "ahead", "distance": "far", "confidence": 0.75 }
    ],
    "lighting_quality": "good",
    "motion_blur_detected": false,
    "raw_response": "Scene: hallway\nText: [301, EXIT ‚Üí]\nLandmarks: [door: left, near, exit_sign: ahead, far]\nLighting: good\nMotion: stable"
  }
}
```

### File Storage

```
observations/
‚îî‚îÄ‚îÄ observations_device_1737172331234_abc123xyz.json
    [
      { device_id: "...", timestamp: "...", gps_latitude: ..., metadata: {...} },
      { device_id: "...", timestamp: "...", gps_latitude: ..., metadata: {...} },
      ...
    ]
```

## Key Differences from Emergency Prompt

| Aspect | Emergency Prompt | Indoor Localization Prompt |
|--------|------------------|----------------------------|
| **Purpose** | Detect hazards for evacuation | Extract visual observations for navigation |
| **Focus** | Fire, smoke, water, obstacles | Scene type, text, landmarks, lighting |
| **Output** | JSON with hazard objects | Structured text format |
| **Use Case** | Emergency response | Indoor positioning, navigation |
| **Data Saved** | Hazard locations | Room numbers, landmarks, scene context |

## What's Working

‚úÖ **Device ID System**: Unique IDs generated and persisted
‚úÖ **GPS Tracking**: Real-time latitude/longitude/accuracy
‚úÖ **Indoor Localization Prompt**: Extracts scene, text, landmarks
‚úÖ **Overshoot Integration**: Uses locationDetector settings
‚úÖ **Parse Result**: Converts Overshoot text to structured JSON
‚úÖ **Save Observations**: GPS + metadata saved to device files
‚úÖ **Observation Storage**: Device-specific JSON files
‚úÖ **API Endpoints**: /save_observation, /observations, /devices
‚úÖ **Live-Escape UI**: Preserved with backward compatibility

## How It Works (Single Device)

```
1. User opens live-escape UI
   ‚Üì
2. Device ID generated/retrieved from localStorage
   ‚Üì
3. GPS tracking starts automatically
   ‚Üì
4. User clicks "START CAMERA"
   ‚Üì
5. Overshoot SDK loads with indoor localization prompt
   ‚Üì
6. Video analysis runs every ~6 seconds
   ‚Üì
7. Result received (text format)
   ‚Üì
8. parseOvershootResult() extracts structured data
   ‚Üì
9. saveObservation() combines GPS + metadata
   ‚Üì
10. POST /save_observation ‚Üí server
   ‚Üì
11. Saved to observations/observations_<device_id>.json
   ‚Üì
12. Repeat steps 6-11 continuously
```

## Testing

### To Build and Run:

```bash
cd /Users/sujit_uppuluri/nexhacks-winners/live-escape
npm install
npm run build
npm run dev
```

Server starts on: `http://localhost:3000`

### For Mobile Testing (HTTPS Required):

```bash
cloudflared tunnel --url http://localhost:3000
```

Use the HTTPS URL provided.

### Expected Console Output:

```
üÜî Generated new device ID: device_1737172331234_abc123xyz
üìç Starting GPS tracking...
‚úÖ GPS tracking started
üìç GPS: (37.774929, -122.419415) ¬±15.2m
‚úÖ Connected to server
‚úÖ Overshoot SDK loaded successfully
üìä Analysis result: {...}
üìç Indoor metadata: { scene_type: "hallway", text_detected: [...], landmarks: [...] }
üíæ Observation saved: 1 total
```

### Check Saved Observations:

```bash
ls observations/
cat observations/observations_device_*.json | jq
```

## Next Steps (Future Enhancements)

1. **Multi-Device Support**: Add dashboard to view all devices
2. **Real-Time Updates**: WebSocket for live device tracking
3. **Map Visualization**: Plot GPS coordinates on map
4. **Trajectory Analysis**: Analyze movement patterns
5. **Indoor Positioning**: Use landmarks + GPS for better localization

## Summary

Successfully integrated locationDetector's indoor localization technology into live-escape:

- **Prompt**: Changed from emergency evacuation to indoor navigation
- **Data**: Extracts scene type, text, landmarks instead of hazards
- **GPS**: Added real-time coordinate tracking
- **Storage**: Saves observations to device-specific JSON files
- **UI**: Live-escape interface preserved with new backend
- **Single Device**: Focused on single-device use case first

**Status**: ‚úÖ Ready for testing with single device
